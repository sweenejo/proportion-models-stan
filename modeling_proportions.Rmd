---
title: "Modeling proportions in Stan"
author: "Jonathan Sweeney"
date: "10/13/2017"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())
library(rstan)
library(tidyverse)
```

## Why proportions?

The specific example I think about often is how to model the proportion of fish catch attributed to a set of species.  Of course this is far from the only context where modeling proportions is important.  Political scientists often are tasked with modeling the share of votes for each party, and marketing analysts frequently are asked about the factors that affect the market share of particular brands.

For this example, however, I'm going to think of fish.

## Simulate data
```{r}
rtrunc_norm <- function(n, mean, sd, lower = -Inf, upper = +Inf) {
  # This function defines a random sampling procedure for a truncated normal distribution.
  #
  samples <- vector(length = n)
  for (i in 1:n) {
    samples[i] <- rnorm(1, mean, sd)
    while (samples[i] < lower | samples[i] > upper) {
      samples[i] <- rnorm(1, mean, sd)
    }
  }
  return(samples)
}

N <- 100 # Think of this as fishing days.  Each day, some mix of fish is caught.
y1 <- rtrunc_norm(N, 10, 5, lower = 0) # Pounds of fish 1
y2 <- rtrunc_norm(N, 20, 5, lower = 0) # Pounds of fish 2
y3 <- rtrunc_norm(N, 30, 5, lower = 0) # Pounds of fish 3
```

Now, lets calculate the proportion of the daily catch for each fish type. And put it into a data set to be fit by Stan.

```{r}
prop1 <- y1 /(y1 + y2 + y3)
prop2 <- y2 /(y1 + y2 + y3)
prop3 <- y3 /(y1 + y2 + y3)

dat <- list(N = N,
            y1 = y1,
            y2 = y2,
            y3 = y3,
            prop1 = prop1,
            prop2 = prop2,
            prop3 = prop3
            )

hist(dat$prop1)
hist(dat$prop2)
hist(dat$prop3)
```

## Dirichlet model

The code below specifies the Stan code for the Dirichlet model.

```{stan output.var = "dir_model", results = "hide"}
data{
int N;
real prop1[N];
real prop2[N];
real prop3[N];
}
transformed data{
real prop[N,3];
for (i in 1:N) {
prop[i,1] = prop1[i];
prop[i,2] = prop2[i];
prop[i,3] = prop3[i];
}
}
parameters{
  vector<lower = 0>[3] alpha;
}
model{
for (i in 1:N)
target += dirichlet_lpdf(to_vector(prop[i,]) | alpha);
}
generated quantities{
vector[3] post_prop;
post_prop = dirichlet_rng(alpha); // Posterior predictive check.
}
```

Okay, it's all set up.  Let's fit the model

```{r, results = "hide"}
dir_fit <- sampling(dir_model, data = dat)
```

Let's verify our model fit by plotting the alphas and posterior predicted proportions.

```{r}
stan_dens(dir_fit)
```
This actually looks very good.  The posterior predicted densities line up very nicely with the historgrams of the data above.

## Beta model

For the next act, we'll fit the same data to three beta distribution models.  The beta distribution, can be thought of as a univariate Dirichlet, used frequently for modeling single proportional observations.  Here, we'll use three of them because we have three proportions.

The Stan code for the beta model is below.  Note that unlike the Dirichlet distribution, which is specified by a single parameter vector alpha, each beta distribution takes two parameters an alpha and beta.

```{stan output.var = "beta_model", results = "hide"}
data{
int N;
real prop1[N];
real prop2[N];
real prop3[N];
}
transformed data{
real prop[N,3];
for (i in 1:N) {
prop[i,1] = prop1[i];
prop[i,2] = prop2[i];
prop[i,3] = prop3[i];
}
}
parameters{
  vector<lower = 0>[3] alpha;
  vector<lower = 0>[3] beta;
}
model{
for (i in 1:3)
target += beta_lpdf(to_vector(prop[,i]) | alpha[i], beta[i]);
}
generated quantities{
vector[3] post_prop;
for (i in 1:3) {
post_prop[i] = beta_rng(alpha[i], beta[i]); // Posterior predictive check.
}
}
```

```{r, results = "hide"}
beta_fit <- sampling(beta_model, data = dat)
```

Let's take a look at the posterior estimates, and posterior predictions.

```{r}
stan_dens(beta_fit)
```

Although I sampled from three beta distributed parameters that modeled proportional data that summed to 1, my posterior samples don't sum to 1.  Our model therefore doesn't yet accurately represent the data generating process (Thanks to Gelman for introducing me to posterior predictive checks).  We can see this problem by running the following code.

```{r}
beta_fit_data <- as.data.frame(beta_fit)
beta_fit_data$sum <- beta_fit_data$`post_prop[1]`+ beta_fit_data$`post_prop[2]`+ beta_fit_data$`post_prop[3]`
head(beta_fit_data)
```

We have to think more about how we can specify the model to address this problem.  One idea is to model the data as a simplex.

```{stan output.var = "beta_model_simplex", results = "hide"}
data{
int N;
real prop1[N];
real prop2[N];
real prop3[N];
}
transformed data{
simplex[3] prop[N];
for (i in 1:N) {
prop[i,1] = prop1[i];
prop[i,2] = prop2[i];
prop[i,3] = prop3[i];
}
}
parameters{
  vector<lower = 0>[3] alpha;
  vector<lower = 0>[3] beta;
}
model{
for (i in 1:3)
target += beta_lpdf(to_vector(prop[,i]) | alpha[i], beta[i]);
}
generated quantities{
vector[3] post_prop;
for (i in 1:3) {
post_prop[i] = beta_rng(alpha[i], beta[i]); // Posterior predictive check.
}
}
```

```{r, results = "hide"}
beta_fit_simplex <- sampling(beta_model_simplex, data = dat)
```

```{r}
beta_fit_simplex_data <- as.data.frame(beta_fit_simplex)
beta_fit_simplex_data$sum <- beta_fit_simplex_data$`post_prop[1]`+ beta_fit_simplex_data$`post_prop[2]`+ beta_fit_simplex_data$`post_prop[3]`
head(beta_fit_simplex_data)
```

Nope, that didn't work.  However, because we know the data is a simplex, that means we only need to model p-1 parameters.  If we define a beta distribution for the first and second, the third is given.  This means we only need to sample two parameters, and the third will be what's left over, ensuring our posterior predictions sum to 1.

```{stan output.var = "beta_model_2", results = "hide"}
data{
int N;
real prop1[N];
real prop2[N];
}
transformed data{
real prop[N,2];
for (i in 1:N) {
prop[i,1] = prop1[i];
prop[i,2] = prop2[i];
}
}
parameters{
  vector<lower = 0>[2] alpha;
  vector<lower = 0>[2] beta;
}
model{
for (i in 1:2)
target += beta_lpdf(to_vector(prop[,i]) | alpha[i], beta[i]);
}
generated quantities{
vector[2] post_prop;
for (i in 1:2) {
post_prop[i] = beta_rng(alpha[i], beta[i]); // Posterior predictive check.
}
}
```

```{r, results = "hide"}
beta_fit_2 <- sampling(beta_model_2, data = dat)
beta_fit_2_data <- as.data.frame(beta_fit_2)
beta_fit_2_data$p3 <- 1 - (beta_fit_2_data$`post_prop[1]`+ beta_fit_2_data$`post_prop[2]`)
beta_fit_2_data$sum <- beta_fit_2_data$p3+beta_fit_2_data$`post_prop[1]`+ beta_fit_2_data$`post_prop[2]`
head(beta_fit_2_data)
```

## Beta models with predictors

What if we observed predictors of our proportional observations?  Greg Snow introduced a reparameterization needed for a beta regression.  $\alpha=\mu \times \phi$, and $\beta = (1- \mu)\times \phi$.  Then, you just predict $\mu$ using your predictors, making sure to constrain it to be greater than 0.

We'll need to first simulate some additional data for the predictors.  Let's assume the predictor $x$, is positively related to proportion of output 1.

```{r}
x <- 1.5 * y1
dat_x <- list(N = N,
            x = x,
            y1 = y1,
            y2 = y2,
            y3 = y3,
            prop1 = prop1,
            prop2 = prop2,
            prop3 = prop3
            )
```

Now, the new reparameterized Stan model.

```{stan output.var = "beta_model_x", results = "hide"}
data{
int N;
real prop1[N];
real prop2[N];
real x[N];
}
transformed data{
real prop[N,2];
for (i in 1:N) {
prop[i,1] = prop1[i];
prop[i,2] = prop2[i];
}
}
parameters{
  real<lower = 0> alpha2;
  real<lower = 0> beta2;
  real<lower = 0> phi;
  real<lower = 0> mu;
  real<lower = 0> b;
}
transformed parameters{
  real<lower = 0> alpha1;
  real<lower = 0> beta1;
  alpha1 = mu * phi;
  beta1 = (1 - mu) * phi;
}
model{
for (i in 1:N) {
  target += exponential_lpdf(mu | b * x[i]);
  target += beta_lpdf(prop[i,1] | alpha1, beta1);
  target += beta_lpdf(prop[i,2] | alpha2, beta2);
}
}
generated quantities{
vector[2] post_prop;
post_prop[1] = beta_rng(alpha1, beta1); // Posterior predictive check.
post_prop[2] = beta_rng(alpha2, beta2);
}
```

```{r}
beta_fit_x <- sampling(beta_model_x, data = dat_x)
print(beta_fit_x)
stan_dens(beta_fit_x)
```
